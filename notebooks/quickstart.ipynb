{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline Quick Start Guide\n",
    "\n",
    "This notebook demonstrates how to use the NLP Pipeline for sentiment analysis and entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import asyncio\n",
    "from src.pipeline import NLPPipeline\n",
    "from src.models import SentimentAnalyzer, EntityExtractor\n",
    "from src.preprocessing import TextCleaner\n",
    "from src.postprocessing import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"I absolutely love this product! It's amazing and works perfectly.\",\n",
    "    \"The service was terrible. I'm very disappointed.\",\n",
    "    \"It's okay, nothing special but does the job.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiments\n",
    "for text in texts:\n",
    "    result = sentiment_analyzer.predict(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.2f})\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize entity extractor\n",
    "entity_extractor = EntityExtractor()\n",
    "\n",
    "# Example text with entities\n",
    "text = \"\"\"Apple Inc. announced today that Tim Cook will be visiting \n",
    "the new office in San Francisco next Monday. The company plans \n",
    "to invest $1 billion in AI research.\"\"\"\n",
    "\n",
    "# Extract entities\n",
    "entities = entity_extractor.extract_entities(text)\n",
    "\n",
    "print(\"Extracted Entities:\")\n",
    "for entity in entities:\n",
    "    print(f\"- {entity['text']} ({entity['label']}): {entity.get('description', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = NLPPipeline()\n",
    "\n",
    "# Process documents\n",
    "documents = [\n",
    "    {\n",
    "        \"document_id\": \"doc001\",\n",
    "        \"text\": \"Microsoft's Azure cloud platform is fantastic for enterprise solutions.\"\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"doc002\",\n",
    "        \"text\": \"The customer support from Amazon was unhelpful and slow.\"\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"doc003\",\n",
    "        \"text\": \"Google's new AI model performs reasonably well in most tasks.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process batch asynchronously\n",
    "results = await pipeline.process_batch(documents)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"\\nDocument: {result.document_id}\")\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Sentiment: {result.sentiment} (confidence: {result.sentiment_confidence:.2f})\")\n",
    "    print(f\"Entities: {[e['text'] + ' (' + e['label'] + ')' for e in result.entities]}\")\n",
    "    print(f\"Processing time: {result.processing_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a larger batch\n",
    "large_batch = [\n",
    "    \"This product exceeded my expectations! Highly recommend.\",\n",
    "    \"Worst purchase ever. Complete waste of money.\",\n",
    "    \"It's decent for the price.\",\n",
    "    \"Absolutely brilliant! Best investment I've made.\",\n",
    "    \"Not impressed. There are better alternatives.\",\n",
    "    \"Average product with average results.\",\n",
    "    \"Outstanding quality and excellent customer service!\",\n",
    "    \"Disappointed with the quality. Would not buy again.\"\n",
    "]\n",
    "\n",
    "# Process batch\n",
    "results = await pipeline.process_batch(large_batch)\n",
    "\n",
    "# Prepare data for visualization\n",
    "viz_data = [\n",
    "    {\n",
    "        'sentiment': r.sentiment,\n",
    "        'confidence': r.sentiment_confidence,\n",
    "        'text': r.text[:50] + '...' if len(r.text) > 50 else r.text\n",
    "    }\n",
    "    for r in results\n",
    "]\n",
    "\n",
    "# Create visualizer\n",
    "visualizer = Visualizer()\n",
    "\n",
    "# Plot sentiment distribution\n",
    "fig = visualizer.plot_sentiment_distribution(viz_data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline statistics\n",
    "stats = pipeline.get_stats()\n",
    "\n",
    "print(\"Pipeline Performance Metrics:\")\n",
    "print(f\"- Documents processed: {stats['documents_processed']}\")\n",
    "print(f\"- Average processing time: {stats['average_processing_time']:.3f}s\")\n",
    "print(f\"- Throughput: {stats['throughput']:.1f} docs/second\")\n",
    "\n",
    "# Aggregated results\n",
    "agg = stats['aggregated_results']\n",
    "print(\"\\nAggregated Results:\")\n",
    "print(f\"- Total documents: {agg['total_documents']}\")\n",
    "print(f\"- Sentiment distribution: {agg['sentiment_distribution']}\")\n",
    "print(f\"- Total entities: {agg['total_entities']}\")\n",
    "\n",
    "# Shutdown pipeline\n",
    "await pipeline.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Preprocessing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text cleaner\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "# Example messy text\n",
    "messy_text = \"\"\"\n",
    "Check out this AMAZING product!!! üòçüòçüòç \n",
    "Visit https://example.com for more info... \n",
    "Contact us at: support@example.com #BestProduct #AI #NLP\n",
    "\"\"\"\n",
    "\n",
    "# Clean text\n",
    "clean_text = cleaner.clean(messy_text)\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(messy_text)\n",
    "print(\"\\nCleaned text:\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "from src.utils.config import Config\n",
    "\n",
    "# Initialize with custom settings\n",
    "custom_config = Config()\n",
    "custom_config.model.batch_size = 64\n",
    "custom_config.model.max_sequence_length = 256\n",
    "custom_config.processing.num_workers = 8\n",
    "\n",
    "# Save configuration\n",
    "custom_config.save_to_file('custom_config.yaml')\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "custom_pipeline = NLPPipeline('custom_config.yaml')\n",
    "\n",
    "print(\"Custom pipeline configuration loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}